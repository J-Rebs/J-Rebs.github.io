---
layout: post
title: Week 2
---

What’s the purpose of this blog? Well, for starters, I hope it can be a window into my own thought processes and realizations. For anyone who stumbles upon this, I want this to be a way for you to get inside the work I’m doing. For people who might be considering a transition into computer science but aren’t sure what that looks like, I want to give you a chance to see yourself in the work I’m doing to help figure out if you might like it.

These posts cover what I did in a week, but they won’t always be contemporaneous. Also, their length will vary; I’d consider this one on the longer side.

Ok, so day week 1 day 1, I met up with my teammate who I had worked with before on another project, and then we had a meeting with Professor Wu. We started getting oriented to GitHub and the office (lab). Over the course of the week, we had other meetings with the team at the Climate School we work with along with other computer science / data science students working on the project, and we started splitting up the work we needed to do into sub-teams.

To split up the work, we had to understand all the project parts. For the two of us who were new, that meant making sure we could use the prototype tool we are working on this summer.

The tool we are working on is meant to be an open-source insurance toolkit. Open-source means using freely available tools to make a new tool that can be used and modified for free by others under certain conditions. Toolkit means a series of programs in a file structure that be easily modified and deployed as an application on the internet. The purpose of the application is usually to interact with and store data.

Internet applications, the webpages we interact with like a flight booking webpages or movie streaming platforms appear to us as easy to use (hopefully) interfaces. Then you might think ok, each application is a single program. However, most web applications are built on a ‘full stack’ of technologies that create a front end (the user interface) and a back end (the server) behind a web application. Side note, when I first heard full stack, I thought of pancakes…I still do.

You can think of the application you interact with like a living thing. It has some way of interacting with you (the interface), and specialized programs (like muscles, lungs etc.) that communicate behind the scenes to make the interface work. You might be thinking, that seems like a little bit of (or a lot of) a simplification, and it is. There’s a lot I still have to learn about how software systems work but thinking about it this way helps me to realize that anytime I’m coding, I also need to think about how a program interacts with the wider system of which it’s part.

The user interface for our application is built in Svelte, which is a framework that sits on top of JavaScript, HTML, and CSS. JavaScript provides interactivity to websites. HTML is the structure of a website, and CSS is what gives a website **style**. So, we had to spend some time making sure we understood Svelte and could make graphics, text, and functions (interactivity) with it.

The front end though by itself can only do so much. In most cases, it needs a server to provide data to it and do more complex calculations behind the scenes. In our case, the Svelte front end connects with a Python server via Flask. Flask is a Python package (an importable tool), that lets you create and serve web applications. It also provides the ability to do different things when different web routes are entered for a website.

For example, when you write [example.com/index.html](http://example.com/index.html) , the /index.html is recognized by Flask as unique, and you can take specific actions based on that route.

The Python server can also help connect to a database (in our case Postgres) and get data to send back to the website. There are ways to store databases directly in websites too, and we do make use of those. I’ll cover that in later posts.

For our application, the data we want to retrieve is based on user inputs which then need to run models (calculations) on our database. Some models depend on earlier models, which means we need to execute the models in a certain order. To do that, we use the data build tool (DBT) to create Structured Query Language (SQL) statements that run on a database.

DBT is a program, and our team had so far worked mostly with Macs, but two of us new folks were running exclusively on Windows. To get around this and to make the application more extendable in the future, we spent some time using Docker to create containers with everything we need to run DBT. Programs are also kind of like plants, they have certain conditions they need to function well. Computers can be thought of like environments. Some environments might be missing something that the plant needs to work well, so when you try to have the plant take root, it doesn’t do so hot.

Docker is an application that let’s you create containers (like little self-contained environments or greenhouses) where you know your application will always be able to run. If another person also has Docker on their computer, they should be able to run your containers with less issue than doing a native installation of a given program.

Once we had reviewed Svelte, setup Docker and created some how to guides, we had reached the end of week 1.


